{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3b8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy \n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter \n",
    "from langdetect import detect\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem.porter import *\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c7f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = bz2.BZ2File(\"train.ft.txt.bz2\")\n",
    "\n",
    "# limited size to 10,000,000 due to performance issues\n",
    "line_list = train_file.readlines(size=10000000)\n",
    "lines = [x.decode('utf-8') for x in line_list]\n",
    "\n",
    "# Split in two: sentiment and review\n",
    "sentiment = [review.split(\"__label__\")[1][0] for review in lines]\n",
    "reviews = [review.split(\"__label__\")[1][1:]  for review in lines]\n",
    "newlist = []\n",
    "\n",
    "for i in range(len(sentiment)):\n",
    "    newlist.append([sentiment[i], reviews[i]])\n",
    "df = pd.DataFrame(newlist, columns = ['score', 'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752df941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22416 entries, 0 to 22415\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   score   22416 non-null  object\n",
      " 1   review  22416 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 350.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63ef6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    11568\n",
       "1    10848\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05c56ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of punchuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create a list of stop words\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer\n",
    "# parser = English()\n",
    "\n",
    "# Creating tokenzer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating token object \n",
    "    mytokens = nlp(sentence)\n",
    "    \n",
    "    # lemmatizing and converting each token in lower case\n",
    "    mytokens = [ word.lemma_.strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    \n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations and word.isalpha()]\n",
    "    \n",
    "    return mytokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a85bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate preprocessed tokens (lowercase, lemmatize and remove stop-words)\n",
    "df['tokens'] = df['review'].apply(spacy_tokenizer)\n",
    "\n",
    "# number of tokens \n",
    "df['n_tokens'] = df['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6159dced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22368\n",
       "0       48\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the language of each tokens\n",
    "df['language'] = df['review'].apply(detect)\n",
    "df['language'] = df['language'].apply(lambda x: 1 if x == 'en' else 0)\n",
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ff8b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tr...</td>\n",
       "      <td>[stuning, non, gamer, sound, track, beautiful,...</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm re...</td>\n",
       "      <td>[good, soundtrack, read, lot, review, good, ga...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite musi...</td>\n",
       "      <td>[amazing, soundtrack, favorite, music, time, h...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack: I truly like this sound...</td>\n",
       "      <td>[Excellent, Soundtrack, truly, like, soundtrac...</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After H...</td>\n",
       "      <td>[remember, pull, jaw, Floor, hear, play, game,...</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                                             review  \\\n",
       "0     2   Stuning even for the non-gamer: This sound tr...   \n",
       "1     2   The best soundtrack ever to anything.: I'm re...   \n",
       "2     2   Amazing!: This soundtrack is my favorite musi...   \n",
       "3     2   Excellent Soundtrack: I truly like this sound...   \n",
       "4     2   Remember, Pull Your Jaw Off The Floor After H...   \n",
       "\n",
       "                                              tokens  n_tokens  language  \n",
       "0  [stuning, non, gamer, sound, track, beautiful,...        35         1  \n",
       "1  [good, soundtrack, read, lot, review, good, ga...        36         1  \n",
       "2  [amazing, soundtrack, favorite, music, time, h...        59         1  \n",
       "3  [Excellent, Soundtrack, truly, like, soundtrac...        71         1  \n",
       "4  [remember, pull, jaw, Floor, hear, play, game,...        44         1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45996519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "305d6c20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stuning', 'non', 'gamer', 'sound', 'track', 'beautiful', 'paint', 'senery', 'mind', 'recomend', 'people', 'hate', 'vid', 'game', 'music', 'play', 'game', 'Chrono', 'Cross', 'game', 'play', 'good', 'music', 'away', 'crude', 'keyboarding', 'fresh', 'step', 'grate', 'guitar', 'soulful', 'orchestra', 'impress', 'care', 'listen']\n"
     ]
    }
   ],
   "source": [
    "print (df['tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ba90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to use the generated tokens in the vectorizer instead of using reviews sentenses\n",
    "# we are creating a dummy function\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "bow_vector = CountVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None, max_features=1000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18000300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y\n",
    "y = df['score']\n",
    "X = sp.sparse.hstack((bow_vector.fit_transform(df['tokens']),df[['n_tokens','language']].values))\n",
    "X_columns=bow_vector.get_feature_names()+df[['n_tokens','language']].columns.tolist()\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20c34fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Aiken', 'Amazon', 'America', 'American', 'Baby', 'Batman', 'Big', 'Book', 'CD', 'Christian']\n"
     ]
    }
   ],
   "source": [
    "print (X_columns[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a13a858b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[2475  719]\n",
      " [ 610 2921]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.77      0.79      3194\n",
      "           2       0.80      0.83      0.81      3531\n",
      "\n",
      "    accuracy                           0.80      6725\n",
      "   macro avg       0.80      0.80      0.80      6725\n",
      "weighted avg       0.80      0.80      0.80      6725\n",
      "\n",
      "\n",
      "\n",
      "Accuracy :  80.23791821561338\n"
     ]
    }
   ],
   "source": [
    "m = MultinomialNB()\n",
    "\n",
    "# fit the train data into the model\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "# Predicting with test dataset\n",
    "y_pred = m.predict(X_test)\n",
    "\n",
    "#classification report & confusion matrix\n",
    "print(\"Confusion Matrix\\n\",metrics.confusion_matrix(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report\\n\",metrics.classification_report(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy : \",metrics.accuracy_score(y_test,y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f609a",
   "metadata": {},
   "source": [
    "### Using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afd58f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y\n",
    "y = df['score']\n",
    "X = df['review']\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c220d12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer',\n",
       "                                        CountVectorizer(max_features=1000,\n",
       "                                                        tokenizer=<function spacy_tokenizer at 0x000000000F0AE5E0>)),\n",
       "                                       ('classifier', MultinomialNB())]),\n",
       "             param_grid={'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_param = {'vectorizer__ngram_range' : [(1,1),(1,2),(1,3)]}\n",
    "\n",
    "bow_vector = CountVectorizer(tokenizer = spacy_tokenizer, max_features=1000)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Create pipeline \n",
    "pipe = Pipeline ([(\"vectorizer\", bow_vector),\n",
    "                 (\"classifier\", classifier)])\n",
    "\n",
    "cv = GridSearchCV(pipe, grid_param, cv=5)\n",
    "\n",
    "# Model generation\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "575a0b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vectorizer__ngram_range': (1, 1)}\n",
      "0.8126948111212565\n"
     ]
    }
   ],
   "source": [
    "print (cv.best_params_)\n",
    "print (cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b5231e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[2484  710]\n",
      " [ 620 2911]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.78      0.79      3194\n",
      "           2       0.80      0.82      0.81      3531\n",
      "\n",
      "    accuracy                           0.80      6725\n",
      "   macro avg       0.80      0.80      0.80      6725\n",
      "weighted avg       0.80      0.80      0.80      6725\n",
      "\n",
      "\n",
      "\n",
      "Accuracy :  80.22304832713755\n"
     ]
    }
   ],
   "source": [
    "m = cv.best_estimator_\n",
    "\n",
    "# Predicting with test dataset\n",
    "y_pred = m.predict(X_test)\n",
    "\n",
    "#classification report & confusion matrix\n",
    "print(\"Confusion Matrix\\n\",metrics.confusion_matrix(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report\\n\",metrics.classification_report(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy : \",metrics.accuracy_score(y_test,y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5bac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

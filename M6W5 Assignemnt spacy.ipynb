{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f3b8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy \n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize \n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer,SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter \n",
    "from langdetect import detect\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from nltk.stem.porter import *\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97c7f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = bz2.BZ2File(\"train.ft.txt.bz2\")\n",
    "\n",
    "# limited size to 10,000,000 due to performance issues\n",
    "line_list = train_file.readlines(size=10000000)\n",
    "lines = [x.decode('utf-8') for x in line_list]\n",
    "\n",
    "# Split in two: sentiment and review\n",
    "sentiment = [review.split(\"__label__\")[1][0] for review in lines]\n",
    "reviews = [review.split(\"__label__\")[1][1:]  for review in lines]\n",
    "newlist = []\n",
    "\n",
    "for i in range(len(sentiment)):\n",
    "    newlist.append([sentiment[i], reviews[i]])\n",
    "df = pd.DataFrame(newlist, columns = ['score', 'review'])\n",
    "\n",
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "752df941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22416 entries, 0 to 22415\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   score   22416 non-null  object\n",
      " 1   review  22416 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 350.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63ef6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    11568\n",
       "1    10848\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773fc7cc",
   "metadata": {},
   "source": [
    "### Using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b05c56ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of punchuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create a list of stop words\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer\n",
    "# parser = English()\n",
    "\n",
    "# Creating tokenzer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating token object \n",
    "    mytokens = nlp(sentence)\n",
    "    \n",
    "    # lemmatizing and converting each token in lower case\n",
    "    mytokens = [ word.lemma_.strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "    \n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations and word.isalpha()]\n",
    "    \n",
    "    return mytokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a85bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate preprocessed tokens (lowercase, lemmatize and remove stop-words)\n",
    "df['tokens'] = df['review'].apply(spacy_tokenizer)\n",
    "\n",
    "# number of tokens \n",
    "df['n_tokens'] = df['tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6159dced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22367\n",
       "0       49\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate the language of each tokens\n",
    "df['language'] = df['review'].apply(detect)\n",
    "df['language'] = df['language'].apply(lambda x: 1 if x == 'en' else 0)\n",
    "df['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ff8b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tr...</td>\n",
       "      <td>[stuning, non, gamer, sound, track, beautiful,...</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm re...</td>\n",
       "      <td>[good, soundtrack, read, lot, review, good, ga...</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite musi...</td>\n",
       "      <td>[amazing, soundtrack, favorite, music, time, h...</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack: I truly like this sound...</td>\n",
       "      <td>[Excellent, Soundtrack, truly, like, soundtrac...</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After H...</td>\n",
       "      <td>[remember, pull, jaw, Floor, hear, play, game,...</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                                             review  \\\n",
       "0     2   Stuning even for the non-gamer: This sound tr...   \n",
       "1     2   The best soundtrack ever to anything.: I'm re...   \n",
       "2     2   Amazing!: This soundtrack is my favorite musi...   \n",
       "3     2   Excellent Soundtrack: I truly like this sound...   \n",
       "4     2   Remember, Pull Your Jaw Off The Floor After H...   \n",
       "\n",
       "                                              tokens  n_tokens  language  \n",
       "0  [stuning, non, gamer, sound, track, beautiful,...        35         1  \n",
       "1  [good, soundtrack, read, lot, review, good, ga...        36         1  \n",
       "2  [amazing, soundtrack, favorite, music, time, h...        59         1  \n",
       "3  [Excellent, Soundtrack, truly, like, soundtrac...        71         1  \n",
       "4  [remember, pull, jaw, Floor, hear, play, game,...        44         1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45996519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "305d6c20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stuning', 'non', 'gamer', 'sound', 'track', 'beautiful', 'paint', 'senery', 'mind', 'recomend', 'people', 'hate', 'vid', 'game', 'music', 'play', 'game', 'Chrono', 'Cross', 'game', 'play', 'good', 'music', 'away', 'crude', 'keyboarding', 'fresh', 'step', 'grate', 'guitar', 'soulful', 'orchestra', 'impress', 'care', 'listen']\n"
     ]
    }
   ],
   "source": [
    "print (df['tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7ba90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to use the generated tokens in the vectorizer instead of using reviews sentenses\n",
    "# we are creating a dummy function\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "bow_vector = CountVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun,\n",
    "    token_pattern=None, max_features=1000)  \n",
    "\n",
    "vec = bow_vector.fit_transform(df['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18000300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y\n",
    "y = df['score']\n",
    "#X = sp.sparse.hstack((bow_vector.fit_transform(df['tokens']),df[['n_tokens','language']].values))\n",
    "#X_columns=bow_vector.get_feature_names()+df[['n_tokens','language']].columns.tolist()\n",
    "\n",
    "df_vec = pd.DataFrame(vec.todense(), columns=bow_vector.get_feature_names())\n",
    "\n",
    "X = pd.concat([df[['n_tokens','language']], df_vec], axis=1)\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a401b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>Aiken</th>\n",
       "      <th>Amazon</th>\n",
       "      <th>America</th>\n",
       "      <th>American</th>\n",
       "      <th>Baby</th>\n",
       "      <th>Batman</th>\n",
       "      <th>Big</th>\n",
       "      <th>Book</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>wow</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_tokens  language  Aiken  Amazon  America  American  Baby  Batman  Big  \\\n",
       "0        35         1      0       0        0         0     0       0    0   \n",
       "1        36         1      0       0        0         0     0       0    0   \n",
       "2        59         1      0       0        0         0     0       0    0   \n",
       "3        71         1      0       0        0         0     0       0    0   \n",
       "4        44         1      0       0        0         0     0       0    0   \n",
       "\n",
       "   Book  ...  world  worth  wow  write  writer  writing  wrong  year  yes  \\\n",
       "0     0  ...      0      0    0      0       0        0      0     0    0   \n",
       "1     0  ...      0      1    0      1       0        0      0     1    0   \n",
       "2     0  ...      0      1    0      0       0        0      0     1    0   \n",
       "3     0  ...      0      0    0      0       0        0      0     0    0   \n",
       "4     0  ...      0      0    0      1       0        0      0     0    0   \n",
       "\n",
       "   young  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc5c42fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[2475  719]\n",
      " [ 610 2921]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.77      0.79      3194\n",
      "           2       0.80      0.83      0.81      3531\n",
      "\n",
      "    accuracy                           0.80      6725\n",
      "   macro avg       0.80      0.80      0.80      6725\n",
      "weighted avg       0.80      0.80      0.80      6725\n",
      "\n",
      "\n",
      "\n",
      "Accuracy :  80.23791821561338\n"
     ]
    }
   ],
   "source": [
    "m = MultinomialNB()\n",
    "\n",
    "# fit the train data into the model\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "# Predicting with test dataset\n",
    "y_pred = m.predict(X_test)\n",
    "\n",
    "#classification report & confusion matrix\n",
    "print(\"Confusion Matrix\\n\",metrics.confusion_matrix(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report\\n\",metrics.classification_report(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy : \",metrics.accuracy_score(y_test,y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a84ad9",
   "metadata": {},
   "source": [
    "### Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8251284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_sent</th>\n",
       "      <th>n_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tr...</td>\n",
       "      <td>[ Stuning even for the non-gamer: This sound t...</td>\n",
       "      <td>[Stuning, even, for, the, non-gamer, :, This, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm re...</td>\n",
       "      <td>[ The best soundtrack ever to anything., : I'm...</td>\n",
       "      <td>[The, best, soundtrack, ever, to, anything, .,...</td>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite musi...</td>\n",
       "      <td>[ Amazing!, : This soundtrack is my favorite m...</td>\n",
       "      <td>[Amazing, !, :, This, soundtrack, is, my, favo...</td>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack: I truly like this sound...</td>\n",
       "      <td>[ Excellent Soundtrack: I truly like this soun...</td>\n",
       "      <td>[Excellent, Soundtrack, :, I, truly, like, thi...</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After H...</td>\n",
       "      <td>[ Remember, Pull Your Jaw Off The Floor After ...</td>\n",
       "      <td>[Remember, ,, Pull, Your, Jaw, Off, The, Floor...</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                                             review  \\\n",
       "0     2   Stuning even for the non-gamer: This sound tr...   \n",
       "1     2   The best soundtrack ever to anything.: I'm re...   \n",
       "2     2   Amazing!: This soundtrack is my favorite musi...   \n",
       "3     2   Excellent Soundtrack: I truly like this sound...   \n",
       "4     2   Remember, Pull Your Jaw Off The Floor After H...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [ Stuning even for the non-gamer: This sound t...   \n",
       "1  [ The best soundtrack ever to anything., : I'm...   \n",
       "2  [ Amazing!, : This soundtrack is my favorite m...   \n",
       "3  [ Excellent Soundtrack: I truly like this soun...   \n",
       "4  [ Remember, Pull Your Jaw Off The Floor After ...   \n",
       "\n",
       "                                              tokens  n_sent  n_tokens  \n",
       "0  [Stuning, even, for, the, non-gamer, :, This, ...       7        87  \n",
       "1  [The, best, soundtrack, ever, to, anything, .,...       4       109  \n",
       "2  [Amazing, !, :, This, soundtrack, is, my, favo...       4       165  \n",
       "3  [Excellent, Soundtrack, :, I, truly, like, thi...       4       145  \n",
       "4  [Remember, ,, Pull, Your, Jaw, Off, The, Floor...       5       109  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['sentences'] = df1['review'].apply(sent_tokenize)\n",
    "df1['tokens'] = df1['review'].apply(word_tokenize)\n",
    "df1['n_sent'] = df1['sentences'].apply(len)\n",
    "df1['n_tokens'] = df1['tokens'].apply(len)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3626bee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    22368\n",
       "0       48\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['language'] = df1['review'].apply(detect)\n",
    "df1['language'] = df1['language'].apply(lambda x: 1 if x == 'en' else 0)\n",
    "df1['language'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c1403bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords/digits/punctuations\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer =SnowballStemmer('english',ignore_stopwords=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    word_tokens = word_tokenize(text)\n",
    "    _stopwords = set(stopwords.words('english') + list(punctuations))\n",
    "    clean_text = [w for w in word_tokens if w.isalpha() and w not in _stopwords] \n",
    "    lemma_text = [lemmatizer.lemmatize(w,pos=\"v\") for w in clean_text]\n",
    "    stem_text = [stemmer.stem(w) for w in lemma_text]\n",
    "    return stem_text\n",
    "\n",
    "df1['clean_tokens'] = df1['review'].apply(clean_text)\n",
    "df1['n_clean_tokens'] = df1['clean_tokens'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d90b572",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "      <th>sentences</th>\n",
       "      <th>tokens</th>\n",
       "      <th>n_sent</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>language</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>n_clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tr...</td>\n",
       "      <td>[ Stuning even for the non-gamer: This sound t...</td>\n",
       "      <td>[Stuning, even, for, the, non-gamer, :, This, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>[stun, even, sound, track, beauti, paint, sene...</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm re...</td>\n",
       "      <td>[ The best soundtrack ever to anything., : I'm...</td>\n",
       "      <td>[The, best, soundtrack, ever, to, anything, .,...</td>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>[best, soundtrack, ever, anyth, read, lot, rev...</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite musi...</td>\n",
       "      <td>[ Amazing!, : This soundtrack is my favorite m...</td>\n",
       "      <td>[Amazing, !, :, This, soundtrack, is, my, favo...</td>\n",
       "      <td>4</td>\n",
       "      <td>165</td>\n",
       "      <td>1</td>\n",
       "      <td>[amaz, soundtrack, favorit, music, time, hand,...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack: I truly like this sound...</td>\n",
       "      <td>[ Excellent Soundtrack: I truly like this soun...</td>\n",
       "      <td>[Excellent, Soundtrack, :, I, truly, like, thi...</td>\n",
       "      <td>4</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>[excel, soundtrack, truli, like, soundtrack, e...</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After H...</td>\n",
       "      <td>[ Remember, Pull Your Jaw Off The Floor After ...</td>\n",
       "      <td>[Remember, ,, Pull, Your, Jaw, Off, The, Floor...</td>\n",
       "      <td>5</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>[rememb, pull, jaw, floor, hear, play, game, k...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  score                                             review  \\\n",
       "0     2   Stuning even for the non-gamer: This sound tr...   \n",
       "1     2   The best soundtrack ever to anything.: I'm re...   \n",
       "2     2   Amazing!: This soundtrack is my favorite musi...   \n",
       "3     2   Excellent Soundtrack: I truly like this sound...   \n",
       "4     2   Remember, Pull Your Jaw Off The Floor After H...   \n",
       "\n",
       "                                           sentences  \\\n",
       "0  [ Stuning even for the non-gamer: This sound t...   \n",
       "1  [ The best soundtrack ever to anything., : I'm...   \n",
       "2  [ Amazing!, : This soundtrack is my favorite m...   \n",
       "3  [ Excellent Soundtrack: I truly like this soun...   \n",
       "4  [ Remember, Pull Your Jaw Off The Floor After ...   \n",
       "\n",
       "                                              tokens  n_sent  n_tokens  \\\n",
       "0  [Stuning, even, for, the, non-gamer, :, This, ...       7        87   \n",
       "1  [The, best, soundtrack, ever, to, anything, .,...       4       109   \n",
       "2  [Amazing, !, :, This, soundtrack, is, my, favo...       4       165   \n",
       "3  [Excellent, Soundtrack, :, I, truly, like, thi...       4       145   \n",
       "4  [Remember, ,, Pull, Your, Jaw, Off, The, Floor...       5       109   \n",
       "\n",
       "   language                                       clean_tokens  n_clean_tokens  \n",
       "0         1  [stun, even, sound, track, beauti, paint, sene...              42  \n",
       "1         1  [best, soundtrack, ever, anyth, read, lot, rev...              44  \n",
       "2         1  [amaz, soundtrack, favorit, music, time, hand,...              67  \n",
       "3         1  [excel, soundtrack, truli, like, soundtrack, e...              68  \n",
       "4         1  [rememb, pull, jaw, floor, hear, play, game, k...              46  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a90e080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stun', 'even', 'sound', 'track', 'beauti', 'paint', 'seneri', 'mind', 'well', 'would', 'recomend', 'even', 'peopl', 'hate', 'vid', 'game', 'music', 'play', 'game', 'chrono', 'cross', 'game', 'ever', 'play', 'best', 'music', 'back', 'away', 'crude', 'keyboard', 'take', 'fresher', 'step', 'grate', 'guitar', 'soul', 'orchestra', 'would', 'impress', 'anyon', 'care', 'listen']\n"
     ]
    }
   ],
   "source": [
    "print (df1['clean_tokens'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d200a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['clean_review'] = df1['clean_tokens'].apply(' '.join)\n",
    "bow_vector = CountVectorizer(max_features=1000) \n",
    "\n",
    "vec = bow_vector.fit_transform(df1['clean_review']) \n",
    "df_vec = pd.DataFrame(vec.todense(), columns=bow_vector.get_feature_names())\n",
    "\n",
    "X = pd.concat([df1[['language','n_clean_tokens']], df_vec], axis=1)\n",
    "y = df1['score']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2972dedd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>n_clean_tokens</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>across</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>wow</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>wrong</th>\n",
       "      <th>year</th>\n",
       "      <th>yes</th>\n",
       "      <th>yet</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   language  n_clean_tokens  abil  abl  absolut  account  accur  across  act  \\\n",
       "0         1              42     0    0        0        0      0       0    0   \n",
       "1         1              44     0    0        0        0      0       0    0   \n",
       "2         1              67     0    0        1        0      0       0    0   \n",
       "3         1              68     0    0        0        0      0       0    0   \n",
       "4         1              46     0    0        0        0      0       0    0   \n",
       "\n",
       "   action  ...  worth  would  wow  write  writer  wrong  year  yes  yet  young  \n",
       "0       0  ...      0      2    0      0       0      0     0    0    0      0  \n",
       "1       0  ...      1      1    0      1       0      0     1    0    0      0  \n",
       "2       0  ...      1      1    0      0       0      0     1    0    0      0  \n",
       "3       0  ...      0      0    0      0       0      0     0    0    0      0  \n",
       "4       0  ...      0      0    0      1       0      0     0    0    0      0  \n",
       "\n",
       "[5 rows x 1002 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ef79238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[2533  661]\n",
      " [ 620 2911]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.79      0.80      3194\n",
      "           2       0.81      0.82      0.82      3531\n",
      "\n",
      "    accuracy                           0.81      6725\n",
      "   macro avg       0.81      0.81      0.81      6725\n",
      "weighted avg       0.81      0.81      0.81      6725\n",
      "\n",
      "\n",
      "\n",
      "Accuracy :  80.95167286245353\n"
     ]
    }
   ],
   "source": [
    "m = MultinomialNB()\n",
    "\n",
    "# fit the train data into the model\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "# Predicting with test dataset\n",
    "y_pred = m.predict(X_test)\n",
    "\n",
    "#classification report & confusion matrix\n",
    "print(\"Confusion Matrix\\n\",metrics.confusion_matrix(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report\\n\",metrics.classification_report(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy : \",metrics.accuracy_score(y_test,y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f609a",
   "metadata": {},
   "source": [
    "### Using pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afd58f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X & y - this model doesn't factor n_tokens & language\n",
    "y = df1['score']\n",
    "X = df1['clean_review']\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c220d12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('vectorizer',\n",
       "                                        CountVectorizer(max_features=1000)),\n",
       "                                       ('classifier', MultinomialNB())]),\n",
       "             param_grid={'vectorizer__ngram_range': [(1, 1), (1, 2), (1, 3)]})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_param = {'vectorizer__ngram_range' : [(1,1),(1,2),(1,3)]}\n",
    "\n",
    "bow_vector = CountVectorizer(max_features=1000)\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Create pipeline \n",
    "pipe = Pipeline ([(\"vectorizer\", bow_vector),\n",
    "                 (\"classifier\", classifier)])\n",
    "\n",
    "cv = GridSearchCV(pipe, grid_param, cv=5)\n",
    "\n",
    "# Model generation\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "575a0b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vectorizer__ngram_range': (1, 3)}\n",
      "0.8220630847226985\n"
     ]
    }
   ],
   "source": [
    "print (cv.best_params_)\n",
    "print (cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b5231e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      " [[2541  653]\n",
      " [ 619 2912]]\n",
      "\n",
      "\n",
      "Classification Report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.80      0.80      3194\n",
      "           2       0.82      0.82      0.82      3531\n",
      "\n",
      "    accuracy                           0.81      6725\n",
      "   macro avg       0.81      0.81      0.81      6725\n",
      "weighted avg       0.81      0.81      0.81      6725\n",
      "\n",
      "\n",
      "\n",
      "Accuracy :  81.08550185873607\n"
     ]
    }
   ],
   "source": [
    "m = cv.best_estimator_\n",
    "\n",
    "# Predicting with test dataset\n",
    "y_pred = m.predict(X_test)\n",
    "\n",
    "#classification report & confusion matrix\n",
    "print(\"Confusion Matrix\\n\",metrics.confusion_matrix(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Classification Report\\n\",metrics.classification_report(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy : \",metrics.accuracy_score(y_test,y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22c09a3",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95402ba",
   "metadata": {},
   "source": [
    "- Although the dataset contains reviews in multiple languages, the ratio of English review is 99.8% while the ratio of other languages is 0.2% only. \n",
    "- In reality, we should consider parsing the articles based on their language but since we are setting max_features to 1000 and other languanges represent only 0.2% of all reviews, I don't think it will affect the accuracy of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0870bbb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
